# Contributing to Agent SRE

Thank you for your interest in contributing to Agent SRE! This project brings site reliability engineering practices to AI agent systems. This guide will help you get set up and make your first contribution.

---

## Table of Contents

- [Getting Started](#-getting-started)
- [Development Setup](#-development-setup)
- [Code Style](#-code-style)
- [Making Changes](#-making-changes)
- [Testing](#-testing)
- [Issue Guidelines](#-issue-guidelines)
- [Architecture Overview](#-architecture-overview)
- [Getting Help](#-getting-help)

---

## ğŸš€ Getting Started

### Fork and Clone

```bash
# 1. Fork the repository on GitHub, then clone your fork
git clone https://github.com/<your-username>/agent-sre.git
cd agent-sre

# 2. Add upstream remote
git remote add upstream https://github.com/imran-siddique/agent-sre.git

# 3. Install in development mode
pip install -e ".[dev]"

# 4. Run tests to verify your setup
python -m pytest

# 5. Install pre-commit hooks
pip install pre-commit
pre-commit install

# 6. Verify the CLI works
agent-sre --help
```

### Pre-commit Hooks

This project uses [pre-commit](https://pre-commit.com/) to enforce code quality on every commit. The hooks include:

- **Trailing whitespace** and **end-of-file** fixes
- **YAML validation** and **merge conflict** detection
- **Private key detection** (security)
- **Ruff** linting and formatting
- **mypy** type checking (excludes tests)
- **pytest** check on push

Hooks are configured in `.pre-commit-config.yaml`. After installing with `pre-commit install`, they run automatically on `git commit`.

---

## ğŸ› ï¸ Development Setup

### Python Version

Agent SRE requires **Python 3.10 or higher** and supports Python 3.10, 3.11, 3.12, and 3.13. We recommend using [pyenv](https://github.com/pyenv/pyenv) to manage Python versions:

```bash
pyenv install 3.12
pyenv local 3.12
```

### Virtual Environment

Always use a virtual environment for development:

```bash
python -m venv .venv

# Linux/macOS
source .venv/bin/activate

# Windows
.venv\Scripts\activate

# Install all dev dependencies
pip install -e ".[dev]"
```

### Optional Extras

Depending on what you're working on, install additional extras:

```bash
pip install -e ".[dev,api]"        # FastAPI server components
pip install -e ".[dev,otel]"       # OpenTelemetry OTLP exporter
pip install -e ".[dev,langchain]"  # LangChain integration
pip install -e ".[dev,datadog]"    # Datadog integration
pip install -e ".[dev,langfuse]"   # Langfuse observability
pip install -e ".[dev,all]"        # Everything
```

### IDE Recommendations

- **VS Code** with the [Python](https://marketplace.visualstudio.com/items?itemName=ms-python.python), [Ruff](https://marketplace.visualstudio.com/items?itemName=charliermarsh.ruff), and [mypy](https://marketplace.visualstudio.com/items?itemName=ms-python.mypy-type-checker) extensions
- **PyCharm** Professional with built-in type checking enabled
- Enable format-on-save with Ruff for consistent formatting

---

## ğŸ“ Code Style

### Formatting and Linting

We use **Ruff** for linting and formatting, and **mypy** for type checking:

```bash
# Format code
ruff format .

# Lint (with auto-fix)
ruff check . --fix

# Type check
mypy src/
```

### Rules

| Rule | Details |
|------|---------|
| **Line length** | 100 characters maximum |
| **Target version** | Python 3.10 |
| **Type hints** | Required on all function signatures |
| **Docstrings** | Required for all public modules, classes, and functions |
| **Docstring style** | Google style |
| **Import order** | Enforced by Ruff (`I` rule) â€” stdlib â†’ third-party â†’ local |
| **Lint rules** | `E`, `F`, `W`, `I`, `N`, `UP`, `B`, `SIM`, `TCH` |

### Type Hints

All function signatures must include type hints. Use `from __future__ import annotations` for modern syntax:

```python
from __future__ import annotations

from agent_sre.slo.types import SLOResult

def evaluate_slo(
    agent_id: str,
    window_hours: int = 24,
    *,
    include_error_budget: bool = True,
) -> SLOResult:
    """Evaluate SLO compliance for an agent over a time window.

    Args:
        agent_id: The unique identifier of the agent to evaluate.
        window_hours: The lookback window in hours.
        include_error_budget: If True, include error budget calculations.

    Returns:
        The SLO evaluation result with compliance status and metrics.

    Raises:
        AgentNotFoundError: If the agent_id does not exist.
    """
    ...
```

### Docstrings (Google Style)

```python
class ChaosExperiment:
    """A fault injection experiment for testing agent resilience.

    Defines and executes controlled failure scenarios against agent
    systems to validate reliability and recovery behavior.

    Attributes:
        name: Human-readable experiment name.
        fault_type: The type of fault to inject (latency, error, kill).
        target: The agent or service to target.

    Example:
        >>> experiment = ChaosExperiment(
        ...     name="latency-spike",
        ...     fault_type="latency",
        ...     target="billing-agent",
        ... )
        >>> result = experiment.run(duration_seconds=60)
    """
```

---

## ğŸ”€ Making Changes

### Branch Naming

Create a branch from `main` using one of these prefixes:

| Prefix | Use For |
|--------|---------|
| `feat/` | New features (e.g., `feat/canary-rollout-strategy`) |
| `fix/` | Bug fixes (e.g., `fix/slo-window-calculation`) |
| `docs/` | Documentation changes (e.g., `docs/chaos-engine-guide`) |
| `test/` | Test additions/improvements (e.g., `test/cost-guard-edge-cases`) |
| `refactor/` | Code refactoring (e.g., `refactor/incident-detector`) |

```bash
# Sync with upstream before branching
git fetch upstream
git checkout -b feat/my-feature upstream/main
```

### Commit Messages

We follow [Conventional Commits](https://www.conventionalcommits.org/):

```
<type>(<scope>): <description>

[optional body]

[optional footer(s)]
```

**Types:** `feat`, `fix`, `docs`, `test`, `refactor`, `chore`, `ci`, `perf`

**Scopes** (optional): `slo`, `replay`, `delivery`, `chaos`, `cost`, `incidents`, `cli`, `api`, `tracing`, `adapters`

**Examples:**

```
feat(slo): add latency percentile objectives
fix(chaos): prevent concurrent experiment conflicts
docs: add runbook authoring guide
test(cost): add budget overflow edge cases
perf(replay): optimize trace deserialization
```

### Pull Request Process

1. **Fork** the repository and create your branch
2. **Make changes** following the code style guidelines
3. **Write/update tests** â€” all new features need test coverage
4. **Run the full check suite:**
   ```bash
   ruff format .
   ruff check .
   mypy src/
   python -m pytest
   ```
5. **Push** your branch and open a Pull Request
6. **Fill out the PR description** with:
   - What changed and why
   - How to test the changes
   - Which engine/module is affected
   - Related issue numbers (e.g., `Closes #61`)
7. **Address review feedback** â€” maintainers may request changes
8. **Merge** â€” a maintainer will merge once approved

### Review Criteria

PRs are evaluated on:
- Correctness and edge case handling
- Test coverage for new/changed behavior
- Type safety (mypy must pass with `--strict`)
- Documentation for public APIs
- Engine independence (engines should work standalone)

---

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
python -m pytest

# Run with verbose output
python -m pytest -v

# Run a specific test file
python -m pytest tests/test_slo_spec.py -v

# Run a specific test
python -m pytest tests/test_chaos_scheduler.py::test_schedule_experiment -v

# Run unit tests only
python -m pytest tests/unit/ -v

# Run integration tests only
python -m pytest tests/integration/ -v

# Run with coverage report
python -m pytest --cov=src/agent_sre --cov-report=html --cov-report=term-missing
```

### Writing Tests

- **Test file location:** Place tests in `tests/` at the repo root; use `tests/unit/` for unit tests and `tests/integration/` for integration tests
- **Naming convention:** `test_<module>.py` for files, `test_<behavior>` for functions
- **Async tests:** Use `pytest-asyncio` â€” tests are auto-detected (`asyncio_mode = "auto"`)
- **Adapter tests:** Each observability adapter (LangFuse, Datadog, Arize, etc.) has its own test file

```python
import pytest
from agent_sre.slo import SLODefinition, SLOEvaluator

class TestSLOEvaluator:
    """Tests for SLO evaluation logic."""

    def test_slo_passes_within_threshold(self) -> None:
        slo = SLODefinition(
            name="latency-p99",
            target=0.999,
            window_hours=24,
        )
        evaluator = SLOEvaluator(slo)
        result = evaluator.evaluate(current_value=0.9995)
        assert result.is_compliant is True

    def test_slo_fails_below_threshold(self) -> None:
        slo = SLODefinition(
            name="availability",
            target=0.999,
            window_hours=24,
        )
        evaluator = SLOEvaluator(slo)
        result = evaluator.evaluate(current_value=0.990)
        assert result.is_compliant is False

    @pytest.mark.asyncio
    async def test_async_slo_evaluation(self) -> None:
        slo = SLODefinition(name="throughput", target=100.0)
        result = await slo.evaluate_async(agent_id="test-agent")
        assert result.error_budget_remaining >= 0
```

### Coverage Requirements

- **Minimum coverage:** 80% for new code
- **Core engines** (SLO, chaos, incidents): aim for 90%+
- Run `python -m pytest --cov=src/agent_sre --cov-report=term-missing` to identify uncovered lines

### Test Organization

```
tests/
â”œâ”€â”€ unit/                       # Fast, isolated unit tests
â”œâ”€â”€ integration/                # Integration tests (may need services)
â”œâ”€â”€ test_slo_spec.py            # SLO engine tests
â”œâ”€â”€ test_chaos_scheduler.py     # Chaos engine tests
â”œâ”€â”€ test_cost_optimizer.py      # Cost guard tests
â”œâ”€â”€ test_alerts.py              # Alert system tests
â”œâ”€â”€ test_experiments.py         # Experiment framework tests
â”œâ”€â”€ test_fleet.py               # Fleet management tests
â”œâ”€â”€ test_langchain_callback.py  # LangChain adapter tests
â”œâ”€â”€ test_langfuse.py            # Langfuse adapter tests
â”œâ”€â”€ test_datadog.py             # Datadog adapter tests
â””â”€â”€ ...                         # 35+ test modules
```

---

## ğŸ“‹ Issue Guidelines

### Bug Reports

When filing a bug, include:

1. **Agent SRE version** (`pip show agent-sre`)
2. **Python version** (`python --version`)
3. **Operating system**
4. **Steps to reproduce** â€” minimal code snippet or CLI commands
5. **Expected behavior** vs. **actual behavior**
6. **Full error traceback** if applicable
7. **Which engine** is affected (SLO, Chaos, Delivery, etc.)

### Feature Requests

For feature requests, describe:

1. **Use case** â€” what reliability problem does this solve?
2. **Proposed solution** â€” how should it work?
3. **Alternatives considered** â€” what else did you look at?
4. **Which engine** should this belong to (or is it a new module)?

### Good First Issues

New to the project? Look for issues labeled:

| Label | Description |
|-------|-------------|
| [`good first issue`](https://github.com/imran-siddique/agent-sre/labels/good%20first%20issue) | Small, well-defined tasks for newcomers |
| [`documentation`](https://github.com/imran-siddique/agent-sre/labels/documentation) | Improve docs, examples, and guides |
| [`help wanted`](https://github.com/imran-siddique/agent-sre/labels/help%20wanted) | Community contributions welcome |

---

## ğŸ—ï¸ Architecture Overview

### Project Structure

```
agent-sre/
â”œâ”€â”€ src/agent_sre/           # Main package
â”‚   â”œâ”€â”€ slo/                 # SLO Engine â€” defines & measures agent reliability
â”‚   â”œâ”€â”€ replay/              # Replay Engine â€” deterministic capture & replay
â”‚   â”œâ”€â”€ delivery/            # Delivery Engine â€” progressive rollouts (canary, blue-green)
â”‚   â”œâ”€â”€ chaos/               # Chaos Engine â€” fault injection testing
â”‚   â”œâ”€â”€ cost/                # Cost Guard â€” budget management & anomaly detection
â”‚   â”œâ”€â”€ incidents/           # Incident Manager â€” detection & response
â”‚   â”œâ”€â”€ alerts/              # Alert routing and deduplication
â”‚   â”œâ”€â”€ adapters/            # Observability platform adapters
â”‚   â”œâ”€â”€ api/                 # FastAPI REST endpoints
â”‚   â”œâ”€â”€ benchmarks/          # Performance benchmarking framework
â”‚   â”œâ”€â”€ cascade/             # Cascade failure detection
â”‚   â”œâ”€â”€ certification/       # Agent certification workflows
â”‚   â”œâ”€â”€ cli/                 # Command-line interface
â”‚   â”œâ”€â”€ evals/               # Evaluation framework
â”‚   â”œâ”€â”€ experiments/         # Experiment tracking
â”‚   â”œâ”€â”€ fleet/               # Fleet-wide agent management
â”‚   â”œâ”€â”€ integrations/        # Third-party integrations
â”‚   â”œâ”€â”€ k8s/                 # Kubernetes operator support
â”‚   â”œâ”€â”€ mcp/                 # MCP server for tool exposure
â”‚   â”œâ”€â”€ specs/               # Specification definitions
â”‚   â”œâ”€â”€ tracing/             # Distributed tracing
â”‚   â””â”€â”€ providers.py         # Dependency injection providers
â”œâ”€â”€ operator/                # Kubernetes operator
â”œâ”€â”€ specs/                   # YAML spec definitions
â”œâ”€â”€ examples/                # Working demos and usage examples
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ tests/                   # Test suite (35+ test modules)
â”œâ”€â”€ benchmarks/              # Benchmark configurations
â”œâ”€â”€ charts/                  # Helm charts
â”œâ”€â”€ dashboards/              # Grafana dashboards
â””â”€â”€ deployments/             # Deployment configurations
```

### Core Engines

Each engine can be used independently or composed together for full-stack reliability:

| Engine | Module | Purpose | Key Abstractions |
|--------|--------|---------|------------------|
| **SLO Engine** | `slo/` | Define and measure agent reliability targets | `SLODefinition`, `SLOEvaluator`, `ErrorBudget` |
| **Replay Engine** | `replay/` | Deterministic capture and replay of agent traces | `TraceCapture`, `ReplaySession`, `GoldenTrace` |
| **Delivery Engine** | `delivery/` | Progressive rollouts with automated rollback | `Canary`, `BlueGreen`, `RolloutPolicy` |
| **Chaos Engine** | `chaos/` | Fault injection for resilience testing | `ChaosExperiment`, `FaultInjector`, `GameDay` |
| **Cost Guard** | `cost/` | Budget tracking and cost anomaly detection | `BudgetPolicy`, `CostTracker`, `AnomalyDetector` |
| **Incident Manager** | `incidents/` | Automated incident detection and response | `IncidentDetector`, `Runbook`, `EscalationPolicy` |

### Supporting Modules

| Module | Purpose |
|--------|---------|
| **adapters** | Connectors for Langfuse, Datadog, Arize, Helicone, W&B, MLflow, etc. |
| **alerts** | Alert routing, deduplication, and persistence |
| **cascade** | Cascade failure detection across agent dependencies |
| **certification** | Automated agent certification against SLO standards |
| **fleet** | Fleet-wide management and coordination |
| **tracing** | OpenTelemetry-based distributed tracing |

---

## ğŸ’¬ Getting Help

- **Questions?** Open a [Discussion](https://github.com/imran-siddique/agent-sre/discussions)
- **Found a bug?** Open an [Issue](https://github.com/imran-siddique/agent-sre/issues)
- **Security issue?** See [SECURITY.md](SECURITY.md)

---

## ğŸ“œ License

By contributing, you agree that your contributions will be licensed under the [MIT License](LICENSE).
