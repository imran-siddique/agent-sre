{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLO Exploration Notebook\n",
    "\n",
    "An interactive walkthrough of **Service Level Objectives** for AI agent systems\n",
    "using `agent-sre`.\n",
    "\n",
    "We will:\n",
    "1. Define SLOs for latency, accuracy, and cost\n",
    "2. Simulate 200 agent calls with varying performance\n",
    "3. Compute SLI values and inspect error budgets\n",
    "4. Visualize compliance, burn rate, and latency distribution\n",
    "5. Check alert thresholds\n",
    "6. Run a what-if analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ‚Äî Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from agent_sre import SLO, ErrorBudget\n",
    "from agent_sre.slo.indicators import (\n",
    "    CostPerTask,\n",
    "    ResponseLatency,\n",
    "    TaskSuccessRate,\n",
    "    ToolCallAccuracy,\n",
    ")\n",
    "from agent_sre.slo.objectives import ExhaustionAction, SLOStatus\n",
    "from agent_sre.slo.dashboard import SLODashboard\n",
    "\n",
    "random.seed(42)\n",
    "print(\"Setup complete ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ‚Äî Define SLOs\n",
    "\n",
    "We create three SLIs and combine them into a single SLO with an error budget.\n",
    "\n",
    "| Indicator | Target | Window | Description |\n",
    "|---|---|---|---|\n",
    "| Response Latency (p95) | ‚â§ 3 000 ms | 1 h | 95th-percentile latency |\n",
    "| Tool-Call Accuracy | ‚â• 99 % | 24 h | Fraction of correct tool selections |\n",
    "| Cost per Task | ‚â§ $0.50 | 24 h | Average USD cost per task |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SLI definitions ---\n",
    "latency_sli = ResponseLatency(target_ms=3000.0, percentile=0.95, window=\"1h\")\n",
    "accuracy_sli = ToolCallAccuracy(target=0.99, window=\"24h\")\n",
    "cost_sli = CostPerTask(target_usd=0.50, window=\"24h\")\n",
    "\n",
    "# --- Error budget (5 %) ---\n",
    "budget = ErrorBudget(\n",
    "    total=0.05,\n",
    "    burn_rate_alert=2.0,\n",
    "    burn_rate_critical=10.0,\n",
    "    exhaustion_action=ExhaustionAction.FREEZE_DEPLOYMENTS,\n",
    ")\n",
    "\n",
    "# --- SLO ---\n",
    "slo = SLO(\n",
    "    name=\"code-review-agent\",\n",
    "    description=\"Reliability targets for an AI code-review agent\",\n",
    "    indicators=[latency_sli, accuracy_sli, cost_sli],\n",
    "    error_budget=budget,\n",
    "    agent_id=\"code-review-agent\",\n",
    ")\n",
    "\n",
    "print(slo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 ‚Äî Simulate Traffic\n",
    "\n",
    "Generate **200 mock agent calls** with realistic performance characteristics.\n",
    "Success rate is intentionally set *below* the target to watch the error budget drain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CALLS = 200\n",
    "\n",
    "# We track per-call metrics for later visualization\n",
    "latencies = []\n",
    "accuracies_running = []\n",
    "costs = []\n",
    "good_events = []\n",
    "budget_remaining = []\n",
    "\n",
    "for i in range(NUM_CALLS):\n",
    "    # Simulate outcomes\n",
    "    task_ok = random.random() < 0.92   # 92 % success (below 95 % budget)\n",
    "    tool_ok = random.random() < 0.985  # 98.5 % accuracy (below 99 % target)\n",
    "    latency_ms = max(100, random.gauss(2400, 700))\n",
    "    cost_usd = max(0.01, random.gauss(0.35, 0.15))\n",
    "\n",
    "    # Record into SLIs\n",
    "    accuracy_sli.record_call(tool_ok)\n",
    "    latency_sli.record_latency(latency_ms)\n",
    "    cost_sli.record_cost(cost_usd)\n",
    "\n",
    "    # Record event against error budget\n",
    "    is_good = task_ok and tool_ok\n",
    "    slo.record_event(good=is_good)\n",
    "\n",
    "    # Store for visualization\n",
    "    latencies.append(latency_ms)\n",
    "    accuracies_running.append(accuracy_sli.current_value())\n",
    "    costs.append(cost_usd)\n",
    "    good_events.append(is_good)\n",
    "    budget_remaining.append(slo.error_budget.remaining_percent)\n",
    "\n",
    "print(f\"Simulated {NUM_CALLS} agent calls\")\n",
    "print(f\"  Good events:  {sum(good_events)} / {NUM_CALLS}\")\n",
    "print(f\"  Bad events:   {NUM_CALLS - sum(good_events)} / {NUM_CALLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 ‚Äî Compute SLIs\n",
    "\n",
    "Read the current indicator values computed by `agent-sre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indicator Summary\")\n",
    "print(\"=\" * 55)\n",
    "for ind in slo.indicators:\n",
    "    val = ind.current_value()\n",
    "    comp = ind.compliance()\n",
    "    if val is not None and comp is not None:\n",
    "        met = \"‚úÖ\" if comp >= 0.95 else \"‚ùå\"\n",
    "        print(f\"  {met} {ind.name}\")\n",
    "        print(f\"       Value:      {val:.4f}\")\n",
    "        print(f\"       Target:     {ind.target}\")\n",
    "        print(f\"       Compliance: {comp:.1%}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 ‚Äî Error Budget\n",
    "\n",
    "The error budget tracks how many \"bad\" events we can tolerate before the SLO\n",
    "is breached.  A burn rate > 1√ó means we are consuming budget faster than planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = slo.evaluate()\n",
    "\n",
    "print(\"Error Budget Report\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  SLO Status:          {status.value}\")\n",
    "print(f\"  Budget Total:        {slo.error_budget.total:.2%}\")\n",
    "print(f\"  Budget Consumed:     {slo.error_budget.consumed}\")\n",
    "print(f\"  Budget Remaining:    {slo.error_budget.remaining_percent:.1f}%\")\n",
    "print(f\"  Exhausted?           {slo.error_budget.is_exhausted}\")\n",
    "print(f\"  Burn Rate (1 h):     {slo.error_budget.burn_rate(3600):.1f}√ó\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "if status == SLOStatus.EXHAUSTED:\n",
    "    print(\"  üö® Budget exhausted ‚Äî action: \"\n",
    "          f\"{slo.error_budget.exhaustion_action.value}\")\n",
    "elif status in (SLOStatus.CRITICAL, SLOStatus.WARNING):\n",
    "    print(\"  ‚ö†Ô∏è  SLO at risk ‚Äî consider slowing deployments\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Budget healthy ‚Äî keep shipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 ‚Äî Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "calls = range(1, NUM_CALLS + 1)\n",
    "\n",
    "# --- 6a: Error budget remaining over time ---\n",
    "ax = axes[0, 0]\n",
    "ax.plot(calls, budget_remaining, linewidth=1.5)\n",
    "ax.axhline(y=0, color=\"red\", linestyle=\"--\", label=\"Budget exhausted\")\n",
    "ax.set_title(\"Error Budget Remaining\")\n",
    "ax.set_xlabel(\"Agent Call #\")\n",
    "ax.set_ylabel(\"Remaining (%)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 6b: Latency distribution ---\n",
    "ax = axes[0, 1]\n",
    "ax.hist(latencies, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "ax.axvline(x=3000, color=\"red\", linestyle=\"--\", label=\"Target (3 000 ms)\")\n",
    "p95_val = sorted(latencies)[int(len(latencies) * 0.95)]\n",
    "ax.axvline(x=p95_val, color=\"orange\", linestyle=\"--\",\n",
    "           label=f\"p95 ({p95_val:.0f} ms)\")\n",
    "ax.set_title(\"Latency Distribution\")\n",
    "ax.set_xlabel(\"Latency (ms)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 6c: Running accuracy ---\n",
    "ax = axes[1, 0]\n",
    "ax.plot(calls, accuracies_running, linewidth=1.5, color=\"green\")\n",
    "ax.axhline(y=0.99, color=\"red\", linestyle=\"--\", label=\"Target (99 %)\")\n",
    "ax.set_title(\"Tool-Call Accuracy (running)\")\n",
    "ax.set_xlabel(\"Agent Call #\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 6d: Good vs bad events ---\n",
    "ax = axes[1, 1]\n",
    "cumulative_bad = []\n",
    "running_total = 0\n",
    "for g in good_events:\n",
    "    if not g:\n",
    "        running_total += 1\n",
    "    cumulative_bad.append(running_total)\n",
    "ax.plot(calls, cumulative_bad, linewidth=1.5, color=\"crimson\")\n",
    "ax.set_title(\"Cumulative Bad Events (budget burn)\")\n",
    "ax.set_xlabel(\"Agent Call #\")\n",
    "ax.set_ylabel(\"Bad Events\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(f\"SLO Dashboard ‚Äî {slo.name}\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 ‚Äî Alert Thresholds\n",
    "\n",
    "Burn-rate alerts fire when the budget is being consumed faster than expected.\n",
    "\n",
    "| Alert | Threshold | Severity |\n",
    "|---|---|---|\n",
    "| Fast burn | 2√ó normal rate | ‚ö†Ô∏è Warning |\n",
    "| Critical burn | 10√ó normal rate | üö® Critical |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alert Status\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "current_burn = slo.error_budget.burn_rate(3600)\n",
    "print(f\"  Current burn rate (1 h): {current_burn:.1f}√ó\")\n",
    "print()\n",
    "\n",
    "for alert in slo.error_budget.alerts():\n",
    "    firing = alert.is_firing(current_burn)\n",
    "    icon = \"üîî FIRING\" if firing else \"üîá ok\"\n",
    "    print(f\"  {icon}  {alert.name}  \"\n",
    "          f\"(threshold: {alert.rate:.0f}√ó, severity: {alert.severity})\")\n",
    "\n",
    "print()\n",
    "firing_alerts = slo.error_budget.firing_alerts()\n",
    "if firing_alerts:\n",
    "    print(f\"  ‚Üí {len(firing_alerts)} alert(s) currently firing\")\n",
    "else:\n",
    "    print(\"  ‚Üí No alerts firing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 ‚Äî What-If Analysis\n",
    "\n",
    "**Scenario:** What if latency increases by 20 %?\n",
    "\n",
    "We replay the same calls with inflated latency and compare the impact on the\n",
    "error budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENCY_INCREASE = 1.20  # +20 %\n",
    "\n",
    "# Create a fresh SLO for the what-if scenario\n",
    "wif_latency = ResponseLatency(target_ms=3000.0, percentile=0.95, window=\"1h\")\n",
    "wif_accuracy = ToolCallAccuracy(target=0.99, window=\"24h\")\n",
    "wif_cost = CostPerTask(target_usd=0.50, window=\"24h\")\n",
    "\n",
    "wif_budget = ErrorBudget(\n",
    "    total=0.05,\n",
    "    burn_rate_alert=2.0,\n",
    "    burn_rate_critical=10.0,\n",
    "    exhaustion_action=ExhaustionAction.FREEZE_DEPLOYMENTS,\n",
    ")\n",
    "\n",
    "wif_slo = SLO(\n",
    "    name=\"code-review-agent-whatif\",\n",
    "    indicators=[wif_latency, wif_accuracy, wif_cost],\n",
    "    error_budget=wif_budget,\n",
    "    agent_id=\"code-review-agent\",\n",
    ")\n",
    "\n",
    "# Replay with inflated latency\n",
    "random.seed(42)\n",
    "wif_budget_remaining = []\n",
    "wif_latencies = []\n",
    "\n",
    "for i in range(NUM_CALLS):\n",
    "    task_ok = random.random() < 0.92\n",
    "    tool_ok = random.random() < 0.985\n",
    "    latency_ms = max(100, random.gauss(2400, 700)) * LATENCY_INCREASE\n",
    "    cost_usd = max(0.01, random.gauss(0.35, 0.15))\n",
    "\n",
    "    wif_accuracy.record_call(tool_ok)\n",
    "    wif_latency.record_latency(latency_ms)\n",
    "    wif_cost.record_cost(cost_usd)\n",
    "    wif_slo.record_event(good=task_ok and tool_ok)\n",
    "\n",
    "    wif_latencies.append(latency_ms)\n",
    "    wif_budget_remaining.append(wif_slo.error_budget.remaining_percent)\n",
    "\n",
    "# Compare\n",
    "orig_p95 = sorted(latencies)[int(len(latencies) * 0.95)]\n",
    "wif_p95 = sorted(wif_latencies)[int(len(wif_latencies) * 0.95)]\n",
    "\n",
    "print(\"What-If: Latency +20 %\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Original p95 latency:  {orig_p95:.0f} ms\")\n",
    "print(f\"  What-if p95 latency:   {wif_p95:.0f} ms\")\n",
    "print(f\"  Original budget left:  {budget_remaining[-1]:.1f}%\")\n",
    "print(f\"  What-if budget left:   {wif_budget_remaining[-1]:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Side-by-side chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(calls, budget_remaining, label=\"Baseline\", linewidth=1.5)\n",
    "ax1.plot(calls, wif_budget_remaining, label=\"+20 % latency\",\n",
    "         linewidth=1.5, linestyle=\"--\")\n",
    "ax1.axhline(y=0, color=\"red\", linestyle=\":\", alpha=0.5)\n",
    "ax1.set_title(\"Error Budget Comparison\")\n",
    "ax1.set_xlabel(\"Agent Call #\")\n",
    "ax1.set_ylabel(\"Remaining (%)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.hist(latencies, bins=30, alpha=0.5, label=\"Baseline\", edgecolor=\"black\")\n",
    "ax2.hist(wif_latencies, bins=30, alpha=0.5, label=\"+20 %\", edgecolor=\"black\")\n",
    "ax2.axvline(x=3000, color=\"red\", linestyle=\"--\", label=\"Target\")\n",
    "ax2.set_title(\"Latency Distribution Comparison\")\n",
    "ax2.set_xlabel(\"Latency (ms)\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"What-If Analysis: +20 % Latency\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Adjust the SLO targets and re-run to see how different thresholds change the\n",
    "  error budget dynamics.\n",
    "- Try `ExhaustionAction.CIRCUIT_BREAK` or `ExhaustionAction.THROTTLE` to\n",
    "  explore different exhaustion policies.\n",
    "- Integrate with a real agent using `AgentSRECallback` from\n",
    "  `agent_sre.integrations.langchain.callback`.\n",
    "- See `examples/slo_alerting.py` for a CLI version of this workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
